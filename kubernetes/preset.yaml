apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-launch
  namespace: monitoring
  labels:
    app: prometheus
data:
  LAUNCHARGS: "--config.file=/opt/config/prometheus.yml --storage.tsdb.path=/opt/data --web.enable-lifecycle --web.console.libraries=/opt/console_libraries --web.console.templates=/opt/consoles"
  TZ: "Asia/Shanghai"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-config-main
  namespace: monitoring
  labels:
    app: prometheus
data:
  config_data: |-
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    alerting:
      alertmanagers:
        - static_configs:
            - targets: ["alertmanager-svc:9093"]
    rule_files:
      - "/opt/rules/instance_down.yaml"
    scrape_configs:
      - job_name: "prometheus"
        static_configs:
          - targets: ["localhost:9090"]
      - job_name: "coredns"
        static_configs:
          - targets: ["10.96.0.10:9153"]
      - job_name: "apiserver"
        static_configs:
          - targets: ["10.96.0.1"]
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      - job_name: "node-exporter"
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
        - source_labels: [__address__]
          regex: '(.*):10250'
          replacement: '${1}:9100'
          target_label: __address__
          action: replace
      - job_name: "cadvisor"
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
        metric_relabel_configs:
        - action: replace
          source_labels: [id]
          regex: '^/machine\.slice/machine-rkt\\x2d([^\\]+)\\.+/([^/]+)\.service$'
          target_label: rkt_container_name
          replacement: '${2}-${1}'
        - action: replace
          source_labels: [id]
          regex: '^/system\.slice/(.+)\.service$'
          target_label: systemd_service_name
          replacement: '${1}'
      #- job_name: "etcd"                 #remove comment if you want etcd to be monitored
      #  kubernetes_sd_configs:
      #    - role: endpoints
      #  scheme: http
      #  tls_config:
      #    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      #    insecure_skip_verify: true
      #  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      #  relabel_configs:
      #  - source_labels: [__meta_kubernetes_service_name]
      #    regex: kube-etcd
      #    action: keep
      #  - action: labelmap
      #    regex: __meta_kubernetes_pod_label_(.+)
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-config-rule
  namespace: monitoring
  labels:
    app: prometheus
data:
  config_data: |-
    groups: 
    - name: instance_down
      rules: 
      - alert: instance_down
        expr: up == 0
        for: 15s
        annotations:
           title: "One Instance Down"
           description: 'Instance has been down for more than 1 minute.'
        labels:
          severity: "critical"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: node-exporter-config
  namespace: monitoring
  labels:
    app: node-exporter
data:
  config_data: |-
    "--web.listen-address=0.0.0.0:9100 --path.procfs=/metrics/procfs --path.sysfs=/metrics/sysfs --path.rootfs=/metrics/rootfs --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+)($|/) --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$" 
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
  labels:
    app: alertmanager
data:
  config_data: |-
    global:
      resolve_timeout: 1m 
      smtp_smarthost: 'smtp.qq.com:465' 
      smtp_from: 'xxx@qq.com' 
      smtp_auth_username: 'xxx@qq.com' 
      smtp_auth_password: 'xxx' 
      smtp_hello: '@qq.com' 
      smtp_require_tls: false
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 2m
      receiver: 'xxx'
    receivers:
    - name: 'xxx'
      #webhook_configs:
      #- url: "http://127.0.0.1:5001/" 
      email_configs:
        - to: "xxx@outlook.com"
          send_resolved: true
    #inhibit_rules:
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus-sa
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-role
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - services
  - endpoints
  - pods
  - nodes/proxy
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  - nodes/metrics
  verbs:
  - get
- nonResourceURLs:
  - /metrics
  verbs:
  - get
- apiGroups:
  - "extensions"
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-role
subjects:
- kind: ServiceAccount
  name: prometheus-sa
  namespace: monitoring
